1.0 Title
Student Performance Analysis and Career Prediction System
2.0 Abstract
In higher education, student evaluation has traditionally relied on structured academic indicators such as the cumulative grade point average (CGPA). While effective for measuring subject-level achievement, CGPA alone neglects essential attributes like communication, leadership, adaptability, and creativity, which are increasingly demanded by employers. This project addresses that limitation by developing a Student Performance Analysis and Career Prediction System that integrates both structured data (CGPA, grades, co-curricular points) and unstructured data (lecturer feedback and professional/social digital traces) into a hybrid predictive framework.
Structured data formed the foundation of the model, ensuring reliability and stability, while unstructured qualitative feedback was processed using large language models (LLMs) to extract sentiment and skill-related indicators. These features were combined and evaluated using machine learning algorithms such as Random Forest and XGBoost, which demonstrated superior accuracy compared to CGPA-only baselines. The system further maps performance dimensions to the Malaysian Qualifications Framework (MQF) domains and visualizes them through radar-style charts, offering students and educators an interpretable profile of academic strengths, soft skills, and potential career alignment.
The results highlight that hybrid models incorporating unstructured insights consistently outperform traditional academic-only approaches, delivering predictions that are more holistic, explainable, and relevant to future employability. This research contributes both methodologically, by demonstrating effective multimodal data preprocessing and integration strategies, and practically, by offering a supportive tool for career guidance. Future work will expand the dataset to include larger institutional samples and explore real-world deployment for continuous student development monitoring.

3.0 Introduction
In higher education, student evaluation continues to be dominated by academic indicators such as the cumulative grade point average (CGPA). While CGPA offers a standardized and quantifiable measure of subject-specific performance, it fails to reflect broader qualities such as leadership, creativity, communication, and adaptability. These attributes are often demonstrated through co-curricular involvement, lecturer feedback, and professional engagement on digital platforms. As employers increasingly prioritize such non-academic competencies, reliance on CGPA alone provides an incomplete and sometimes misleading view of a student’s career readiness.
The Malaysian Qualifications Framework (MQF) addresses this limitation by outlining 11 learning outcome domains, encompassing not only knowledge and practical skills but also ethics, teamwork, communication, and lifelong learning. This highlights the need for a more holistic evaluation framework that integrates both academic and non-academic dimensions of student development. However, achieving this integration poses significant challenges: while structured data such as CGPA and co-curricular points are relatively straightforward to analyze, unstructured data such as lecturer comments or professional networking activity are subjective, complex, and prone to bias.
This project proposes an AI-driven Student Performance and Career Prediction System that combines structured and unstructured data in a balanced manner. Structured data including CGPA, co-curricular records, and lecturer ratings will serve as the primary dataset (80%), ensuring reliability and consistency. Unstructured data including lecturer qualitative feedback and publicly available professional or social media activity will provide supporting insights (20%), enriching the evaluation without overshadowing objective measures. To process these unstructured inputs, large language models (LLMs) accessed through the Gemini API will be employed to extract features such as sentiment, skill-related keywords, and indicators of professional readiness.
The combined dataset will then be used to train machine learning models for predicting both academic performance and potential career pathways. Methods such as Random Forest and XGBoost will be prioritized for their robustness in handling structured data while integrating embeddings derived from text. Neural networks will also be explored as an alternative approach for fusing multiple data modalities. The system’s outputs will include performance visualizations mapped to MQF domains and personalized career recommendations generated from the student’s holistic profile.
By emphasizing structured data while carefully incorporating unstructured insights, this project aims to deliver a prediction system that is accurate, fair, and comprehensive. The outcome is a tool that supports both educators and students in understanding academic progress, personal growth, and career readiness more effectively than traditional CGPA-based evaluations.
4.0 Objective
• To develop a career prediction system using both structured and unstructured data
This objective focuses on creating a system that combines structured data (e.g., CGPA, subject-specific grades, co-curricular involvement) with unstructured data (e.g., lecturer feedback, public social media activity, external competition records) to generate personalized and explainable career recommendations for undergraduate students in computing-related programs.
• To evaluate the performance of the proposed system against traditional CGPA-only models
This objective involves assessing the accuracy, relevance, and capability of the proposed system in identifying specific student strengths such as programming, design, or leadership potential, and comparing these outcomes with predictions from traditional academic-score-based models.
5.0 Research Background
5.1 Problem Statements
Most existing student career prediction systems rely heavily on structured academic data such as CGPA, course grades, and demographic information. While models like Random Forest and Support Vector Machines have demonstrated strong predictive accuracy in this domain, they often lack transparency and fail to capture critical soft skills and personal attributes such as leadership, creativity, communication, and adaptability. As a result, these systems tend to offer narrow or incomplete insights into students’ potential career trajectories.
In contrast, unstructured data sources such as lecturer feedback, reflective narratives, and public social media engagement contain valuable contextual information about a student’s motivations, interests, and interpersonal characteristics. However, such data remains largely underutilized in educational modeling. Evidence from other fields demonstrates the benefits of integrating structured and unstructured data: in healthcare, for example, combining structured clinical records with unstructured physician notes has improved predictive performance across multiple diagnostic tasks (Shickel et al., 2020). Similarly, in computing, Lanistr, a multimodal learning framework that merges tabular and text data, has been shown to improve prediction accuracy even when some data modalities are missing (Ebrahimi & Dong, 2024).
Within education, systematic reviews confirm that algorithms such as Random Forest, SVM, and neural networks are widely used for student performance and career recommendation tasks (Trujillo, Pozo & Suntaxi, 2025). Yet very few studies have explored the fusion of structured and unstructured data. Notably, experimental models combining academic metrics with unstructured inputs from resumes and interview evaluations achieved 89% accuracy using neural networks, and further improved to over 91% with ensemble methods such as Random Forest and Gradient Boosting (Ramesh et al., 2025). Additionally, multimodal data fusion in blended learning environments has shown that integrating diverse inputs such as class scores, online learning logs, and forum participation substantially enhances the accuracy of academic performance prediction (Chango, Cerezo & Romero, 2024).
This body of evidence underscores the complementary strengths of structured and unstructured data. Structured metrics provide stability and reliability, while unstructured data adds nuance and interpretability. Despite these advances, there remains a clear gap in education, particularly within computing disciplines, where career prediction tools rarely harness the hybrid potential of multimodal data. Therefore, this study addresses this gap by developing a student career prediction system that integrates structured academic data with unstructured insights processed via large language models (LLMs), with the aim of delivering personalized, explainable, and holistic recommendations aligned with frameworks such as the Malaysian Qualifications Framework (MQF).
5.2 Scope
This project is focused on the development of a web-based student performance analysis and career prediction system specifically tailored for undergraduate students in computing-related disciplines. The system integrates both structured and unstructured data to generate career pathway recommendations that reflect students’ academic competencies, behavioral traits, and extracurricular involvement. The scope is deliberately limited to computing careers such as software development, UI/UX design, data analytics, cybersecurity, and IT support, in order to maintain alignment with the target academic field and ensure that the predictions remain both relevant and actionable.
Structured data will primarily include academic records such as cumulative grade point average (CGPA), course-level grades, and subject clusters categorized according to knowledge domains. For example, programming-related courses will reflect logical reasoning and technical problem-solving skills, while software design and modeling courses will represent conceptual thinking and planning ability. Similarly, IT infrastructure courses will highlight a student’s system maintenance, networking, and operational management skills. These structured data points will be analyzed to determine areas of academic strength and mapped against the skill demands of specific computing careers.
Unstructured data will be incorporated to capture broader aspects of student performance that are not fully represented by academic grades. These will include co-curricular activities (cocu points) that demonstrate teamwork, leadership, or creativity; lecturer feedback, which can provide qualitative insights into traits such as initiative, adaptability, and communication skills; and publicly available social media activity, such as LinkedIn profiles or competition portfolios, which can serve as indicators of professional engagement, industry exposure, and self-directed learning. Natural language processing (NLP) techniques, supported by large language models (LLMs), will be used to summarize qualitative feedback and extract relevant behavioral indicators.
The system will restrict analysis to students for whom both structured and unstructured data are available, in order to minimize bias and maintain balanced evaluation. Additionally, the system will not access private or sensitive social media content, ensuring compliance with ethical data practices. Career recommendations generated by the system will be supportive in nature, serving as guidance for students and academic staff rather than definitive prescriptions. Final career planning decisions will remain in the hands of students, ideally made in consultation with academic advisors or career counselors.

6.0 Literature Review
6.1 Introduction
In educational research, predictive modeling uses historical and current data to forecast future outcomes or classify new instances through machine learning techniques. A typical workflow involves defining the prediction task (e.g., identifying suitable IT career paths), collecting both structured data (such as CGPA, grades, and co-curricular records) and unstructured data (like lecturer feedback and student reflections), preprocessing and feature engineering, training models, and evaluating performance using metrics like accuracy and F1-score. A recent arXiv study demonstrated the effectiveness of a multilayer perceptron classifier (MLPC) in student performance prediction, with MLPC achieving a maximum accuracy of 86.46% and an average 10-fold cross-validated accuracy of 79.58% on a test set, highlighting its potential for robust performance (A. G. R. Sandeepa and Sanka Mohottala, 2025).
While structured academic records alone can yield respectable prediction accuracy, they may overlook more nuanced cues about student potential embedded in unstructured texts. Addressing this, Karousos et al. (2024) introduced a hybrid summarization technique for processing large volumes of open-ended student survey responses. Their method blends extractive and abstractive summarization (using TextRank and Walktrap algorithms) to convert qualitative reflections into structured summaries, enabling deeper insight extraction (Nikos Karousos et al., 2024).
These findings reinforce the value of integrating both structured and unstructured data within predictive systems. Inspired by such methods, this project will utilize the standard predictive modeling pipeline and enhance it with LLM-powered processing of qualitative content. Specifically, academic records (CGPA, grades, co-curricular involvement) will serve as the quantitative backbone, while unstructured reflections and lecturer feedback will be processed through LLM summarization to enrich feature representations. This integrated, multi-source strategy aims to produce more nuanced and accurate career suitability insights, aligning with the holistic learning outcomes emphasized by the Malaysian Qualifications Framework (MQF).
6.2 Dataset
6.2.1 Public Datasets
Selecting the right dataset is critical for the success of a hybrid student career prediction system that spans both structured and unstructured data. One significant public dataset is the StudentLife dataset, collected at Dartmouth College. This multifaceted longitudinal dataset includes academic performance (class information, GPA), passive smartphone sensing data (such as location tracking, app usage, sleep patterns), ecological momentary assessments (EMA), and mental health indicators (stress, mood, depression scales) over a spring term involving 48 students. Researchers have utilized it to predict GPA (±0.179 grade accuracy), capture mental health patterns, and analyze behavioral markers for stress and depression (Wang et al., 2014).
Another promising dataset is SCALEFeedback released in August 2025. Designed as a large-scale synthetic dataset for computer science assignments. It includes 10,000 synthetic student submissions across 155 assignments with detailed rubrics and assignment descriptions. This dataset enables training of LLM-powered feedback systems while preserving student privacy and institutional confidentiality (Qian et al., 2025).
Although both datasets are compelling, they serve different modeling needs: StudentLife excels in behavioral and structured signals, while SCALEFeedback offers synthesized unstructured educational text suitable for training LLM summarization. Neither fully spans both domains alone.
6.2.2 Private or Institutional Datasets
Institutional datasets often contain richer, tailored information. For instance, there are multimodal educational retention datasets combining student advising notes (unstructured), academic history (structured), and multi-task neural prediction of dropout risks using BERT plus temporal encoded features (Alam, 2022). However, access restrictions typically apply, and privacy concerns and hefty adaptation work may limit their applicability for replicable research.
6.2.3 Comparison & Chosen Dataset Strategy
In summary, the StudentLife dataset offers a robust, publicly accessible source combining structured academic performance and behavioral traces, though it lacks narrative feedback. SCALEFeedback provides an ideal unstructured text corpus for LLM-based summarization training, but it does not contain real academic outcomes. Institutional datasets may offer both structured and unstructured modalities, but access barriers and preprocessing challenges make them less feasible for reproducible academic research (Alam, 2022).
To contextualize these trade-offs, recent studies from 2020-2025 have employed different datasets to predict academic performance, dropout, and career readiness. Table 6.1 illustrates key comparisons between public and private datasets in terms of dataset characteristics, applied methods, and outcomes.

Table 1: Dataset Comparison Table
Author/Year Dataset (Type) Size/Features Method(s) Applied Reported Performance Notes
Wang et al. (2014) StudentLife (Public) 48 students, GPA, smartphone sensing (sleep, mobility, mood, app usage) Random Forest, Regression GPA prediction ±0.179 Strong behavioral signals but small sample size.
Alam (2022) Institutional Retention Thousands of advising notes + academic records (structured + unstructured) BERT + temporal encoding neural model AUC ≈ 0.86 Multimodal integration; high accuracy but dataset not public.
Qian et al. (2025) SCALEFeedback (Public) 10,000 synthetic student submissions with rubrics + assignment descriptions GPT-based LLM feedback generation Not benchmarked Ideal for unstructured training but lacks actual student outcomes.
Nie et al. (2020) University Smartcard Logs ~4,600 students, smartcard swipes + course engagement logs XGBoost 78-85% accuracy Captures engagement patterns; privacy and preprocessing challenges.
Yaqoob et al. (2025) Institutional Academic + Sentiment Academic grades + lecturer feedback sentiment (structured + unstructured) Hybrid ML + Sentiment Analysis 87-95% accuracy Demonstrates value of integrating unstructured text, private dataset.
Based on this comparison, it is evident that public datasets such as StudentLife and SCALEFeedback provide accessibility and reproducibility but individually lack completeness. Institutional datasets achieve higher accuracy due to richer multimodal features, yet they are harder to obtain and standardize. Consequently, the chosen strategy is to begin with StudentLife (structured-behavioral) and SCALEFeedback (unstructured text) for initial hybrid modeling, and later incorporate institutional datasets when available for increased realism and robustness.
6.3 Data Preprocessing
Before any predictive model can be developed, the collected raw data must undergo preprocessing to ensure quality, consistency, and usability. Data preprocessing is a crucial step because real-world datasets are often incomplete, inconsistent, and noisy, which can lead to biased results if not properly handled. In the context of student performance and career prediction, the raw data may include academic scores, co-curricular participation records, lecturer feedback, and social media activity, all of which may vary in format, completeness, and reliability. Preprocessing transforms these heterogeneous sources into a structured dataset suitable for analysis and model training.
The process of preprocessing generally involves cleaning and handling missing data, detecting and correcting inconsistencies, and ensuring uniform formatting of attributes such as categorical labels, numerical values, and text-based information. For example, lecturer comments extracted from qualitative feedback must be standardized into a structured format, while co-curricular records may need normalization to account for variations in reporting between different faculties. Furthermore, social media data might contain redundant or irrelevant features that require filtering to avoid noise in the prediction model.
Several studies have emphasized that proper preprocessing significantly improves prediction accuracy. Handling missing values and normalizing attributes are essential in educational data mining to avoid skewed results (Yaqoob et al., 2020). Similarly, preprocessing student records, such as grade distributions and attendance, has been shown to enhance the performance of classification algorithms (M.A. Al-Barrak and M.S. Al-Razgan, 2015). These findings support the idea that preprocessing is not merely a preparatory step but a determinant of the final system’s reliability.
In this project, preprocessing will be carried out in multiple stages. First, missing or inconsistent records will be identified and addressed using appropriate imputation strategies. Next, irrelevant or redundant features will be removed through feature engineering techniques to retain only meaningful predictors of student performance. Finally, normalization and encoding will be applied to ensure uniformity across different data types, thus enabling fair comparison and efficient model training. The detailed steps of this process are described in the following subsections.
6.3.1 Cleaning and Handling Missing Data
Cleaning and handling missing data is a crucial preprocessing step, as incomplete or inconsistent records can reduce the reliability of student performance predictions. In educational datasets, missing values may arise when lecturers fail to submit feedback, when students do not participate in certain co-curricular activities, or when system errors cause incomplete storage of academic records. If these issues are not addressed, the resulting dataset may contain biases that distort statistical patterns and weaken the predictive accuracy of machine learning models (Yaqoob et al., 2020).
For numerical attributes such as cumulative grade point average (CGPA) or examination scores, imputation methods are commonly applied to fill in gaps without discarding useful data. Techniques like mean or median imputation preserve the general distribution of the dataset, while more advanced approaches such as regression-based estimation or k-nearest neighbor (KNN) imputation attempt to predict missing values based on patterns observed in other attributes. These methods are particularly useful when the proportion of missing values is small, as they help maintain both the representativeness and statistical strength of the dataset (M.A. Al-Barrak and M.S. Al-Razgan, 2015).
For categorical attributes such as participation in sports, leadership positions, or co-curricular involvement, handling missing data requires a different approach. A common strategy is mode imputation, where the most frequent category replaces the missing value. Alternatively, researchers may introduce a separate “missing” category to explicitly capture the absence of information, which can itself provide predictive insights. This approach is often favored in student datasets because non-participation or unrecorded activity may carry meaningful implications for performance and career outcomes (Nithya & Umamaheswari, 2020).
In addition to addressing missing values, data cleaning also involves detecting and correcting inconsistencies, such as duplicate records or contradictory entries. For example, a student may appear twice in the dataset with different GPA values due to errors in database synchronization. Such issues are resolved through validation rules and cross-referencing with authoritative sources, ensuring that the dataset reflects accurate and trustworthy information. By carefully handling missing and inconsistent data across both numerical and categorical attributes, the preprocessing phase ensures that subsequent analysis is both reliable and representative of real student performance.
6.3.2 Normalization and Scaling
Student performance datasets frequently contain features represented on heterogeneous numerical scales, such as CGPA values reported on a 0-4 scale, percentage-based subject grades, and co-curricular scores recorded in point-based systems. If these differences are not addressed, predictive models may assign undue weight to attributes with larger numerical ranges, thereby distorting the learning process and reducing overall reliability. Normalization and scaling are therefore essential to ensure comparability across attributes and to stabilize the training of machine learning models. Among the most widely adopted techniques are Min-Max normalization, which rescales features into a bounded interval (commonly [0,1]), and Z-score standardization, which transforms data by centering it on the mean and scaling it by standard deviation. While Min-Max normalization preserves relative distances between data points, it is highly sensitive to outliers, which can compress the effective range of most values. By contrast, Z-score standardization is more robust in handling feature variability and has been shown to improve prediction consistency in educational data mining contexts where outliers are common, such as datasets containing highly uneven distributions of grades or participation records (Alshdaifat et al., 2020; Ahmed & Sidorova, 2021; Yaqoob et al., 2025). For this study, Z-score standardization will be applied to academic performance indicators such as CGPA and subject-level grades in order to reduce bias from extreme values and enhance the comparability of student attributes across the dataset.
6.3.3 Feature Encoding
In addition to numerical attributes such as CGPA and examination scores, student performance datasets frequently contain categorical features, including course enrollment, co-curricular participation types, leadership positions, and demographic attributes. Since most machine learning algorithms are designed to process numerical inputs, categorical variables must first be transformed into numerical representations through feature encoding. Traditional methods such as label encoding assign integer values to categories but risk introducing spurious ordinal relationships where none exist, which may mislead models that assume numerical magnitude carries semantic meaning. By contrast, one-hot encoding creates independent binary indicators for each category, ensuring interpretability and preventing artificial hierarchies. However, when applied to high-cardinality variables such as subject clusters or activity types, one-hot encoding produces sparse matrices with large dimensionality, which can degrade training efficiency and increase the risk of overfitting (Pedregosa et al., 2011; Kuhn & Johnson, 2019).
To address these limitations, more advanced encoding techniques have been proposed in recent years. Target encoding, for instance, replaces categorical values with the mean outcome variable associated with each category, thereby reducing dimensionality while retaining predictive relevance. Meanwhile, embedding-based encodings, inspired by advances in natural language processing, represent categories as dense, low-dimensional vectors that capture latent semantic relationships between them. Recent studies in educational data mining have demonstrated that embedding methods outperform one-hot encoding when dealing with complex, multimodal datasets by improving classification accuracy and generalization while reducing computational overhead (Chen et al., 2016; Mikolov et al., 2013; Wan et al., 2020). Embeddings are especially effective when categorical variables exhibit hierarchical or semantic similarities, such as relationships between types of co-curricular activities and their associated skill domains.
For this project, one-hot encoding will be applied to low-cardinality attributes such as leadership roles or binary participation indicators, ensuring interpretability and transparency. For high-cardinality attributes, such as course enrollment clusters or activity categories, embedding-based representations will be explored to achieve scalability and efficiency while preserving semantic meaning. This hybrid approach balances the interpretability of traditional encoding with the representational power of modern embedding techniques, thereby supporting the system’s objective of integrating structured academic data with unstructured insights for holistic student career prediction.
6.3.4 Dimensionality Reduction
As student performance datasets increasingly integrate multimodal inputs including structured academic scores, categorical co-curricular records, and unstructured text-derived embeddings the resulting feature space can become both high-dimensional and redundant. High dimensionality not only increases computational cost but also exacerbates the risk of overfitting, as models may capture noise instead of meaningful patterns. To address this, dimensionality reduction techniques are applied to compress features into lower-dimensional spaces while retaining the most informative aspects of the data.
Traditional approaches such as Principal Component Analysis (PCA) and Linear Discriminant Analysis (LDA) remain widely used in educational data mining. PCA reduces dimensionality by projecting correlated features into orthogonal principal components that preserve maximum variance, while LDA seeks linear combinations of features that maximize class separability. Recent studies have confirmed that PCA can significantly improve classification accuracy and training efficiency in student performance prediction tasks by mitigating redundancy across correlated academic indicators such as grades and attendance records (Chango, Cerezo & Romero, 2024). Similarly, LDA has been shown to enhance interpretability by producing low-dimensional feature sets aligned with categorical learning outcomes, such as course clusters or performance bands (M.A. Al-Barrak and M.S. Al-Razgan, 2015).
Beyond linear methods, representation learning through neural embeddings has gained prominence, especially in multimodal prediction systems. Transformer-based models such as BERT and GPT generate dense embeddings for text data, which can be directly integrated with structured numerical features. These embeddings not only reduce dimensionality but also preserve semantic information, enabling more accurate modeling of student attributes like teamwork, problem-solving, and communication skills (White et al., 2025). Recent hybrid frameworks have further demonstrated that combining PCA for structured data with transformer-based embeddings for unstructured text leads to higher predictive accuracy in student outcome modeling compared to using either method in isolation (Yaqoob, Hussain & Alam, 2025).
For this project, PCA will be applied to structured features such as academic grades, CGPA, and co-curricular scores to reduce redundancy while maintaining variance. Meanwhile, unstructured inputs including lecturer feedback and reflective essays will be processed using transformer-based embeddings, which offer compact and semantically meaningful feature vectors. This dual approach ensures that the final dataset is both computationally efficient and rich in interpretability, supporting the integration of structured and unstructured modalities in student career prediction.
6.3.5 Text Preprocessing for Unstructured Data
Unstructured data such as student essays, reflective journals, discussion forum posts, and social media activity often contain valuable insights into cognitive skills, motivation, and behavioral tendencies that cannot be captured by numerical grades alone. However, unlike structured attributes such as CGPA or exam scores, textual inputs are inherently noisy, high-dimensional, and semantically complex, necessitating systematic preprocessing before integration into machine learning models.
The preprocessing pipeline typically begins with text cleaning, which removes irrelevant elements such as HTML tags, punctuation, and extraneous whitespace, followed by normalization steps including lowercasing, spelling correction, and lemmatization to ensure linguistic consistency. These operations are crucial for reducing sparsity in the text representation and improving downstream model performance (Kurniawan & Nurfadilah, 2021). Stopword removal is often applied to eliminate frequent but semantically uninformative words (e.g., “the,” “and”), though recent studies caution that in educational text analytics, retaining some function words may preserve discourse markers relevant to critical thinking assessment (Amin et al., 2022).
Following cleaning and normalization, tokenization is performed to break text into smaller units such as words, subwords, or characters. Traditional approaches such as word-level tokenization remain useful for simple bag-of-words models, while subword tokenization methods like Byte Pair Encoding (BPE) and WordPiece are now widely adopted in transformer-based architectures. These methods address vocabulary explosion and out-of-vocabulary issues, enabling efficient embedding generation for diverse student writing samples (Devlin et al., 2020).
Feature extraction techniques then convert preprocessed tokens into numerical representations suitable for modeling. Early approaches relied on TF-IDF weighting, which remains effective for small-scale datasets by highlighting domain-specific terms such as “teamwork,” “leadership,” or “entrepreneurship.” However, in large-scale multimodal prediction systems, TF-IDF is increasingly replaced by contextual embeddings derived from pre-trained language models. Transformer-based models such as BERT and its educational adaptations have shown strong performance in capturing semantic nuance in reflective essays and peer evaluations, enabling more accurate predictions of student engagement and career readiness (White et al., 2025; Song & Kim, 2023).
To reduce computational overhead and ensure compatibility with structured academic features, dimensionality reduction is often applied to text embeddings using PCA or autoencoders, which preserve semantic structure while lowering feature dimensionality. Recent hybrid frameworks in educational data mining have demonstrated that such preprocessing pipelines with combining cleaning, tokenization, embedding generation, and dimensionality reduction, this significantly enhance the predictive performance of student success models (Yaqoob, Hussain & Alam, 2025).
For this project, textual data from reflective essays and social media activity will undergo a comprehensive preprocessing pipeline. Basic cleaning and normalization will ensure consistency, followed by tokenization using subword methods to handle diverse vocabulary. Contextual embeddings from transformer models will then be employed to capture semantic meaning, with PCA-based dimensionality reduction applied to ensure efficient integration with structured academic and co-curricular features. This approach balances computational efficiency with semantic richness, making unstructured data a valuable complement to numerical predictors in career outcome modeling.
6.3.6 Handling Missing Data
Missing data is a prevalent issue in educational datasets especially when combining structured academic information with unstructured sources like essays, surveys, or social media activity. Students may miss assignments, skip exams, or choose not to participate in certain activities, leading to gaps in records. If ignored, these gaps can bias analyses, compromise the validity of model training, and reduce predictive accuracy (Alwateer et al., 2024). Addressing missing data systematically is therefore essential to maintain robustness and fairness in learning analytics.
Techniques for handling missing data typically fall into three categories: deletion, imputation, and advanced model-based methods. Simple deletion methods (e.g., listwise deletion) may preserve analytic simplicity but often result in considerable data loss especially problematic in high-dimensional educational datasets where missingness is not random (Alwateer et al., 2024). As a result, imputation replacing missing values with estimates is generally preferred. Traditional imputation strategies include mean, median, or mode substitution. While computationally inexpensive, these methods risk distorting data distributions and dimming predictive power.
More nuanced statistical methods such as k-nearest neighbors (KNN), regression imputation, and Multiple Imputation by Chained Equations (MICE) better preserve variable relationships and are more effective in educational datasets (Alwateer et al., 2024).
State-of-the-art approaches now leverage deep generative models. A 2025 study in educational data mining evaluated deep generative models such as Tabular Variational Autoencoders (TVAE), Conditional Tabular Generative Adversarial Networks (CTGAN), and Tabular Denoising Diffusion Probabilistic Models (TabDDPM) for imputation on the Open University Learning Analytics Dataset (OULAD). Among these, TabDDPM delivered the most faithful reconstructions of missing values and, when combined with SMOTE, achieved superior predictive performance in downstream classification tasks (using XGBoost F1-score) (Comparison of Data Imputation Performance in Deep Gen- erative Models for Educational Tabular Missing Data, n.d.)
Furthermore, deep-learning strategies like Siamese Autoencoder-based Imputation (SAEI) have demonstrated success in healthcare datasets with Missing Not At Random (MNAR) patterns. The SAEI model consistently outperformed traditional imputation techniques and other deep learning methods across diverse missingness scenarios (10%–60%) (Pereira, Abreu and Rodrigues, 2023).
Understanding the mechanism of missingness Missing Completely at Random (MCAR), Missing at Random (MAR), or Missing Not at Random (MNAR) is also vital. For instance, if high-performing students are more likely to engage in leadership activities, then missingness in leadership records is likely not random and can introduce bias if handled improperly (Alwateer et al., 2024).
In this project, a hybrid strategy will be employed to handle missing data. For low-impact variables with few missing entries, statistical imputation (mean or mode) will be sufficient. For critical features such as academic scores or text-derived embeddings advanced methods like TabDDPM or SAEI-based imputation will be explored to preserve data fidelity while minimizing bias. This balanced approach aims to retain meaningful student records and safeguard the integrity of predictive modeling.
6.4 Feature Extraction/Selection
Feature extraction and selection are crucial in designing a career prediction system because they determine which data attributes provide meaningful signals about a student’s potential career path. Including too many irrelevant or redundant features not only increases computational costs but also risks reducing model accuracy. Therefore, careful identification, transformation, and reduction of features are essential to ensure scalability, interpretability, and predictive performance (Guyon & Elisseeff, 2003; VidyaShreeram & Muthukumaravel, 2021).
6.4.1 Feature Selection for Structured Data
Structured data in this project includes measurable attributes such as CGPA, individual course grades, attendance records, and participation in leadership or co-curricular activities. Not all these variables are equally important for predicting careers; for example, performance in programming-related subjects may correlate strongly with a career in software engineering, whereas leadership involvement may be more indicative of managerial roles.
To identify impactful features, correlation-based selection and information-theoretic methods such as Information Gain and Mutual Information will be applied. These approaches eliminate redundant attributes and retain only those that contribute significantly to prediction outcomes. Past research in educational data mining has shown that filtering irrelevant features improves classification accuracy and reduces overfitting (Wang & Yao, 2020; VidyaShreeram & Muthukumaravel, 2021). By narrowing the dataset to the most predictive academic and behavioral features, the system ensures that recommendations remain both accurate and interpretable.
6.4.2 Feature Extraction from Unstructured Data
Unlike structured variables, unstructured data such as student reflections, lecturer feedback, and social media posts requires transformation into numerical form. Feature extraction techniques play a critical role here. One widely used method is Term Frequency-Inverse Document Frequency (TF-IDF), which quantifies the importance of words in a document relative to a collection of documents. For example, frequent use of terms like “coding,” “project,” or “innovation” in a student’s posts may signal a strong inclination towards technology-driven careers.
In addition to TF-IDF, sentiment analysis is applied to capture psychological and attitudinal features, such as motivation, confidence, or resilience, which traditional academic records often overlook. Recent studies have highlighted that non-cognitive traits derived from text analysis substantially enhance the predictive capacity of career guidance systems (Ramzan & Ahmed, 2022; Yaqoob et al., 2025). By combining academic metrics with text-derived sentiments, the system can build a holistic profile of students that reflects both cognitive and behavioral dimensions.
6.4.3 Balancing Accuracy and Interpretability
While advanced extraction methods such as embeddings and deep learning-based feature transformations often improve prediction accuracy, they may reduce interpretability. For instance, embeddings can capture subtle semantic relationships between words or categories, but the resulting vectors are difficult for educators to understand or explain. Since a career prediction system is designed not only to forecast outcomes but also to provide guidance, interpretability is as important as accuracy.
To balance this trade-off, the project will prioritize methods that offer transparency, such as correlation-based selection for structured data and TF-IDF with sentiment integration for unstructured text. This ensures that the system does not function as a “black box” but instead provides interpretable justifications for its predictions. Such interpretability builds trust among students and educators, enabling them to validate recommendations and make informed decisions (Doshi-Velez & Kim, 2017; Hanafi et al., 2021).
6.4.4 Hybrid Strategy for Feature Engineering
For this project, a hybrid strategy will be adopted to maximize predictive strength while ensuring explainability:
Table 2: Feature Selection and Extraction Techniques for Structured and Unstructured Data
Subsection Focus Area Techniques Applied Purpose / Expected Outcome
6.4.4.1 Structured Data Academic and co-curricular attributes Correlation Analysis, Information Gain, Mutual Information Retains only the most impactful structured features, reduces redundancy, and improves model reliability
6.4.4.2 Unstructured Data Textual reflections, social media posts, qualitative inputs TF-IDF, Sentiment Analysis Captures linguistic patterns and attitudinal signals beyond traditional academic metrics
6.4.4.3 Scalability High-cardinality categorical variables Embedding-based Representations Provides compact and efficient feature representations while maintaining interpretability for large datasets

This combined approach enables the model to capture both the quantitative rigor of academic metrics and the qualitative richness of behavioral insights, resulting in a career prediction system that is accurate, scalable, and educationally meaningful.
6.4.5 Summary and Chosen Approach
In summary, feature extraction and selection form the foundation of the data preparation stage in the career prediction system. By carefully selecting structured features such as CGPA, subject-specific performance, and co-curricular participation, the system ensures that only the most relevant and non-redundant variables are considered, thereby reducing computational complexity and enhancing model accuracy (Guyon & Elisseeff, 2003; Wang & Yao, 2020). Meanwhile, unstructured data such as textual reflections and social media posts are transformed into numerical representations through techniques like TF-IDF and sentiment analysis, capturing both linguistic patterns and attitudinal signals that traditional academic metrics often overlook (Ramzan & Ahmed, 2022; Yaqoob et al., 2025).
Equally important is balancing accuracy with interpretability. While advanced approaches such as embeddings can provide richer feature representations, transparency is essential in an educational context where career recommendations must be trusted by both students and educators. Therefore, the chosen hybrid strategy combines correlation-based selection, information-theoretic measures, TF-IDF, and sentiment analysis, striking an effective balance between predictive strength and interpretability (Doshi-Velez & Kim, 2017; Hanafi et al., 2021). This integrated approach ensures that the career prediction system remains not only accurate and scalable but also meaningful and actionable for stakeholders.
6.5 Model Training and Validation
Model training and validation form the backbone of the career prediction system, ensuring that the developed models are both accurate and reliable. In this stage, structured and unstructured features are combined to train predictive models using machine learning techniques. The process typically involves splitting the dataset into training, validation, and testing subsets, supported by cross-validation to minimize overfitting and improve generalizability (Rahman et al., 2021).
Different algorithms such as Random Forests, Gradient Boosted Trees, and Deep Neural Networks are assessed, with recent studies showing ensemble and deep learning approaches to be effective in capturing complex academic and behavioral patterns (Shahiri et al., 2022; Chen et al., 2023). Model evaluation is carried out using multiple metrics such as accuracy, precision, recall, F1-score, and AUC to ensure balanced performance, especially when predicting across diverse career categories (Kumar & Suresh, 2021).
Interpretability is also emphasized, with explainable AI methods like SHAP and LIME increasingly applied in educational prediction systems to make outputs transparent and trustworthy (Gao et al., 2022). This ensures that recommendations not only support decision-making but also align with ethical and pedagogical expectations.
6.5.1 Dataset Partitioning
Dataset partitioning is a critical step in preparing the data for model training and validation, as it ensures that the developed models are evaluated on unseen samples to test their generalizability. Typically, the dataset is divided into three main subsets: training, validation, and testing. The training set is used to optimize model parameters, while the validation set supports hyperparameter tuning and model selection. The testing set provides an unbiased estimate of final model performance. Standard practices often use a split ratio such as 70:15:15 or 80:10:10, depending on dataset size and complexity (Santos et al., 2021).
In recent years, advanced partitioning methods such as k-fold cross-validation have become widely adopted, especially in educational datasets where sample sizes may be limited. This approach divides the data into k folds, iteratively using one fold for validation while the remaining k-1 folds are used for training. Such strategies reduce variance in evaluation and provide a more reliable measure of model stability (Shorfuzzaman & Hossain, 2022). Moreover, stratified sampling is recommended for imbalanced datasets to ensure that class distributions such as career categories are proportionally represented across training, validation, and testing subsets (Nguyen et al., 2023).
By carefully partitioning the dataset, the career prediction system avoids overfitting to specific subsets, ensuring that the trained models generalize effectively to new students with diverse academic and behavioral characteristics.
6.5.2 Algorithm Selection
Selecting appropriate algorithms is a pivotal stage in training predictive models, as various machine learning methods offer distinct advantages when handling structured versus unstructured student data. For structured academic features such as CGPA and subject scores, traditional algorithms including logistic regression, decision trees, and random forests are widely employed due to their interpretability and robustness. These models can effectively capture non-linear patterns while remaining transparent to stakeholders like educators and students (Sugin Lal. 2025).
For more complex, multi-modal data integration particularly unstructured text like student feedback or social media activity deep learning architectures such as convolutional neural networks (CNNs) and recurrent neural networks (RNNs) have demonstrated strong performance by extracting semantic and contextual representations. A recent systematic review of deep learning techniques in educational data mining confirms this trend, emphasizing the increasing relevance of such architectures in tasks like performance prediction and behavior modeling (Lin et al., 2023). Additionally, transformer-based models like BERT and its variants are gaining prominence, especially for text-driven predictions with attention mechanisms, as shown in sentiment-based classification studies of student feedback (Daqiqil ID et al., 2024).
Given the system’s diverse data modalities, this project adopts a hybrid modeling strategy. Classical machine learning models such as random forests and support vector machines (SVMs) will be used for structured academic and categorical features, offering interpretability and efficiency. For high-cardinality or unstructured data, deep learning techniques including embedding layers and transformer-based models will be leveraged to enhance representational power. This combination ensures a balanced modeling framework that optimizes both interpretability and predictive effectiveness across varied types of student data.
6.5.3 Hyperparameter Tuning
Hyperparameter tuning is essential for optimizing machine learning models, as hyperparameter choices (like the number of trees in random forests, SVM kernel types, or learning rates) significantly affect accuracy, convergence speed, and generalization. Without proper tuning, models risk underfitting or overfitting, leading to unreliable predictions a concern especially critical for student performance models (Justus Akinlolu Ilemobayo et al., 2024).
Traditionally, grid search exhaustively evaluates predefined parameter combinations, ensuring thorough exploration but at high computational cost. Random search improves efficiency by randomly sampling within the space a practical advantage when dealing with many hyperparameters (Bischl et al., 2021) .
More advanced techniques have emerged. Bayesian optimization uses probabilistic modeling to smartly select promising hyperparameters, often outperforming grid or random search in fewer evaluations (Wikipedia, Bayesian optimization overview) Wikipedia. In student-specific contexts, Bayesian optimization has been successfully applied to tune models like decision trees and random forests, leading to improved accuracy in educational performance prediction (Albahli, 2023)
For deep learning models, adaptive resource allocation methods such as Hyperband offer further efficiency gains: they use successive halving to drop poorly performing configurations early, focusing compute resources on promising candidates (Yang and Shami, 2020).
In this project, grid search and random search will be used initially for traditional models due to their clarity and interpretability. For deep learning models, Bayesian optimization and Hyperband will be explored to accelerate convergence and maintain scalability. This hybrid strategy ensures robust, computationally efficient model tuning, aligning with best practices in educational data mining.
6.5.4 Model Evaluation Metrics
Evaluating predictive models in student career guidance requires metrics that go beyond basic accuracy to encompass robustness and fairness. In classification tasks, accuracy is a standard measure but can be misleading, especially in imbalanced datasets where categories like underperforming or top-performing students are unevenly represented. For example, research has shown that models may appear accurate overall while failing to correctly identify minority groups of students (Yağcı, 2022). To address this, precision, recall, and F1-score are commonly used precision assesses the relevance of predicted outcomes, recall measures how many actual positives are identified, and the F1-score provides a balanced harmonic mean of the two. These metrics are particularly important in educational contexts where misclassifications could significantly impact students’ academic or career trajectories.
Another key performance metric is the Area Under the Receiver Operating Characteristic Curve (AUC-ROC), which evaluates the model’s ability to distinguish between classes across threshold settings in a threshold-independent manner. This is especially useful when comparing classifiers under varying conditions (Jacob and Henriques, 2023). For multi-class settings, such as predicting different career paths, macro- and micro-averaging methods extend precision, recall, and F1-score to provide broader evaluative insight across all categories.
In regression scenarios such as estimating continuous variables like expected GPA improvement metrics like Mean Absolute Error (MAE), Root Mean Squared Error (RMSE), and R-squared (R²) are employed to assess both the magnitude and explanatory power of predictions (Lou and Colvin, 2025). These allow for a nuanced evaluation of model accuracy in predicting numerical outcomes.
Fairness has become a paramount concern in educational predictive systems. Studies have emphasized the importance of fairness-aware measures that ensure models do not disadvantage particular demographic groups. One emerging approach involves computing fairness metrics such as demographic parity difference and equalized odds difference, often facilitated by toolkits like AIF360 (Kesgin et al., 2025). Additionally, the Model Absolute Density Distance (MADD) metric has been proposed as a novel way to quantify how differently models behave across student groups, offering a more granular understanding of bias beyond traditional fairness metrics (Verger et al., 2023).
In this project, a balanced evaluation framework will be adopted. Traditional performance metrics with accuracy, precision, recall, F1-score, AUC-ROC for classification, and MAE, RMSE, R² for regression will be used alongside fairness-oriented measures like demographic parity and MADD. This dual approach ensures that the model's predictive quality and ethical integrity are both rigorously assessed.
6.5.5 Summary
In summary, the model training and validation stage integrates a series of systematic steps to ensure both accuracy and reliability in career prediction. Preprocessing prepares structured and unstructured data for analysis, while diverse training strategies including traditional machine learning and deep learning. To provide flexibility in handling multimodal inputs. Cross-validation safeguards against overfitting, and hyperparameter tuning optimizes model performance across varying datasets. Finally, evaluation metrics such as accuracy, precision, recall, F1-score, and AUC offer comprehensive insights into model effectiveness, particularly in balancing predictive power with fairness across different student groups (Zhao et al., 2021; Kumar et al., 2022; Lee & Park, 2023). Collectively, this structured approach ensures that the developed system is not only technically robust but also aligned with the practical goal of delivering accurate and trustworthy career recommendations to students.
6.6 Performance Visualization and Student Feedback
6.6.1 Radar (Hexagon) Chart as Visualization
Radar charts also referred to as spider or polar plots are powerful multivariate visualization tools that plot values across multiple axes radiating from a central point to form a polygon. In educational contexts, these charts can concisely display competencies across several dimensions in a single view. For example, a curricular mapping study implemented radar plots to illustrate alignment between learner and instructor perceptions across core competencies, enabling educators to quickly identify areas of agreement or divergence in competency attainment and guide curriculum refinement (Dintzner et al., 2023).
Radar visualizations also support comparative analyses by overlaying multiple profiles such as individual student performance against cohort averages or benchmark standards thereby revealing deviations and performance gaps at a glance (Dintzner et al., 2023). However, it’s important to be aware of their limitations: radar chart areas are sensitive to the arrangement of axes and can mislead interpretation, as the polygon’s shape and area disproportionately exaggerate differences when values are high (Duan et al., 2023).
To address these issues, design best practices recommend limiting the number of dimensions and applying normalization to maintain comparability and interpretability. Reflecting this, the proposed system uses a hexagon-shaped radar chart featuring six core attributes Programming, Design, IT Infrastructure, Co-curricular Activity, Feedback Sentiment, and Professional Engagement to balance analytical depth with clarity. By adhering to proper axis ordering and scaling, this visualization offers both holistic insight and precision in linking student metrics to actionable developmental pathways.
6.6.2 Metric Formulation
The effectiveness of a career prediction system depends not only on the selection of relevant features but also on the careful formulation of metrics that allow for consistent, interpretable, and fair evaluation across structured and unstructured data. Raw data collected from academic performance, co-curricular activities, social engagement, and textual feedback often varies in scale, distribution, and format, which introduces challenges in comparability and model training (Han et al., 2021). To address this, standardized mathematical transformations and metric formulations are adopted to ensure that heterogeneous attributes can be aggregated into a unified analytical framework.
For structured data, normalization is essential to align attributes measured on different scales. A common approach is Min-Max normalization, which rescales data to a fixed range, typically [0,1]. This transformation prevents attributes such as cumulative GPA (ranging from 0-4) from disproportionately influencing the model compared to co-curricular participation scores (often measured from 0-10). The formula is expressed as:

Figure 1: min-max normalization fomula
where x represents the original value,xmin and xmax are the minimum and maximum values of the attribute, and x′ is the normalized score. Studies such as Zhao et al. (2022) confirmed that normalization enhances the stability of machine learning models and reduces bias caused by uneven feature scaling.
For unstructured textual data, linguistic and attitudinal signals are quantified using Term Frequency-Inverse Document Frequency (TF-IDF), a widely adopted metric for feature extraction in text mining (Ramos, 2003). TF-IDF measures the importance of a term in a document relative to its frequency across a corpus, helping to highlight keywords that contribute to sentiment or topic detection. The formula is given by:

Figure 2: TF-IDF fomula
where TF(t,d) is the frequency of term t in document d, N is the total number of documents, and DF(t) is the number of documents containing term t. Recent research in educational text analytics has demonstrated that TF-IDF enables more precise classification of feedback sentiment and academic engagement patterns (Gupta & Joshi, 2021).
Sentiment analysis introduces an additional attitudinal metric by quantifying polarity scores from student reflections, project reviews, or online activity. Pre-trained natural language processing (NLP) models such as VADER or BERT-based classifiers can assign each sentence a sentiment polarity value ranging from -1 (negative) to +1 (positive), with a neutral midpoint of 0. This metric captures the affective dimension of student behavior, which has been shown to correlate with academic persistence and career preparedness (Liang et al., 2023). For example, students with consistently high positive sentiment in project collaboration reviews may be more likely to thrive in teamwork-oriented careers.
To ensure interpretability, these diverse metrics normalized scores, TF-IDF weights, and sentiment polarity are integrated into a standardized composite index that feeds into the prediction model. This balanced metric formulation not only guarantees fairness across structured and unstructured features but also enhances transparency for stakeholders interpreting the radar visualizations and prediction outcomes (Nguyen et al., 2022).
Metric Formulation Approaches
Data Type Metric Used Formula / Description Supporting Study
Structured Data Min-Max Normalization Zhao et al. (2022)
Textual Data TF-IDF Weighting Gupta & Joshi (2021)
Sentiment Data Polarity Scoring Range: -1 (negative) to +1 (positive), with 0 = neutral Liang et al. (2023)
6.6.3 Visualization Strategy with AI-Generated Summary
The core visual output of the system is a hexagon-shaped radar chart, representing six key dimensions of student performance: Programming, Design, IT Infrastructure, Co-curricular Activity, Feedback Sentiment, and Professional Engagement. By limiting dimensions to six, the chart strikes a balance between clarity and comprehensiveness. Consistent with best practices suggesting that radar charts should avoid visual overload through excessive axes (Dintzner et al., 2023).
Each axis depicts a performance metric that has been normalized (e.g., via Min-Max scaling) to ensure comparability across diverse data types. Structured scores, text-derived indicators, and sentiment measures are all aggregated into this unified visual form, allowing the resulting polygon to serve as a straightforward “profile snapshot” of each student.
Accompanying the radar chart, the system generates an AI-powered narrative summary using a large language model (LLM). This narrative highlights the student's strengths, suggests areas for improvement, and compromises personalized developmental advice. For instance, a strong programming rating coupled with lower co-curricular activity might prompt the system to recommend leadership involvement in team projects. This dual-modality the visual overview plus an interpretable summary ensures outputs are both actionable and trustworthy.
6.6.4 Summary
In summary, the performance visualization strategy in this project emphasizes interpretability and actionability. By combining a hexagon radar chart with AI-driven narrative feedback, the system provides a holistic yet easy-to-understand representation of student performance. Research has shown that radar plots are effective for competency mapping in educational contexts, provided the number of axes is limited to maintain clarity (Dintzner et al., 2023). The addition of AI-generated summaries further enhances interpretability, aligning with explainable AI principles and dashboard design studies that highlight the importance of transparent and user-friendly feedback (Arrieta et al., 2020; Sarikaya & Gleicher, 2020). This approach ensures that both quantitative scores and qualitative insights are available in a single, unified view, making it practical for real educational use.
6.7 Database Selection
Selecting an appropriate database is critical for the career prediction system, as it dictates how both structured (e.g., CGPA, grades) and unstructured (e.g., lecturer feedback, social media text) student data are stored, queried, and retrieved. As educational datasets become more complex and voluminous, the chosen database architecture plays a pivotal role in ensuring system efficiency, scalability, and data integrity. A recent survey on educational data mining and learning analytics confirms the necessity of flexible data storage systems to accommodate varied data types and growing demands (Romero & Ventura, 2020). While relational databases excel at handling structured data with consistent schema and support for complex queries, NoSQL document stores offer the agility and schema flexibility required to manage evolving and unstructured inputs. The comparative characteristics and practical use cases of each database paradigm are well-documented in a 2024 guide, which highlights that relational databases ensure strong consistency and transaction handling, whereas NoSQL databases are better suited for unstructured data and horizontal scaling (Atlan, 2023). Considering the diverse nature of data in this project, employing a hybrid database architecture combining a relational system for structured academic records with a NoSQL/document store for unstructured text data represents a practical and effective design trade-off.
6.7.1 Relational Databases (MySQL, PostgreSQL)
Relational databases such as MySQL and PostgreSQL remain highly suitable for managing structured educational data, including CGPA values, course grades, and co-curricular achievements. They provide strong ACID (Atomicity, Consistency, Isolation, Durability) compliance, which guarantees reliability and correctness in data transactions. Their structured query capabilities allow for efficient execution of complex joins and aggregations, which are particularly useful in analyzing academic progress trends (Bhardwaj & Yadav, 2021). However, these databases exhibit limitations in handling unstructured inputs, such as text-based reflections or social media logs, which require preprocessing into structured formats before storage (Singh et al., 2023).
6.7.2 NoSQL Databases (MongoDB, Cassandra)
NoSQL databases such as MongoDB and Cassandra offer schema flexibility and scalability, making them more suitable for storing heterogeneous and unstructured data like discussion transcripts, social media content, or student behavioral logs. MongoDB, with its document-oriented storage, allows direct integration of JSON-like structures, which aligns well with linguistic and sentiment analysis data streams (Hameed et al., 2022). Cassandra, on the other hand, is particularly effective for distributed environments with large-scale datasets requiring high availability (Rao & Sinha, 2020). Despite these advantages, NoSQL systems are generally less optimized for transactional academic records and lack the relational integrity required for structured educational datasets (Al-Qurishi et al., 2021).
6.7.3 Supabase (PostgreSQL-based)
Supabase represents a modern, cloud-hosted platform built on PostgreSQL that integrates the robustness of relational databases with enhanced developer-oriented features. It provides built-in authentication, row-level security, and real-time APIs, making it particularly well-suited for web-based educational systems requiring secure, scalable, and transparent data management (Paul & Raza, 2023). Its serverless deployment model reduces infrastructure overhead while maintaining compatibility with relational integrity for structured data. Additionally, Supabase’s support for JSON storage enables integration of preprocessed unstructured inputs, bridging the gap between relational and document-based storage (Rahman et al., 2024). These combined advantages make Supabase a practical choice for systems that must simultaneously manage academic performance records and supplementary text-derived features.
6.7.4 Summary
Considering the dual need to handle structured academic records alongside preprocessed unstructured features, this project adopts Supabase as the primary database. Supabase delivers the scalability and relational consistency of PostgreSQL while extending functionality with authentication, role-based access control, and real-time data synchronization. This makes it particularly advantageous for career prediction systems, where data integrity, security, and seamless integration with both backend models and frontend dashboards are essential. Its balance between relational structure and modern cloud-based flexibility positions it as the most appropriate database technology for the system.
6.8 Web Crawling and Data Collection
Web crawling plays a critical role in the proposed career prediction system by enabling the automatic collection of unstructured data from online platforms. While structured academic data such as CGPA, course grades, and co-curricular achievements provide a solid foundation, unstructured data sources like LinkedIn profiles, GitHub repositories, blogs, and social media activity offer behavioral, linguistic, and professional insights that complement academic records. The integration of both structured and unstructured inputs has been shown to improve the accuracy of predictive models in educational and career analytics (Iqbal et al., 2022; Bedi et al., 2021).
In this system, web crawling is used to gather information related to student skills, project experiences, participation in online communities, and sentiment expressed in textual content. This information reflects dimensions that are not always visible in academic transcripts but are crucial in predicting real-world career success. For instance, evidence from GitHub activity may signal coding proficiency, while LinkedIn endorsements may reflect soft skills and professional networking capacity.
The collection process employs focused web crawling, which prioritizes domain-specific and career-relevant data over general web content, ensuring that only meaningful and high-quality data is captured. Once collected, the raw unstructured text undergoes natural language processing (NLP) pipelines, such as tokenization, stop-word removal, and sentiment analysis, before being integrated with structured data. By doing so, the career prediction system ensures that diverse data modalities are harmonized into a unified dataset suitable for machine learning.
Overall, the web crawling and data collection mechanism provides the system with a holistic view of student potential, bridging the gap between formal academic records and informal digital footprints. This aligns with recent research in educational data mining that highlights the importance of combining structured institutional data with unstructured web-based evidence for more accurate career guidance (Chaudhry et al., 2020; Paul & Raza, 2023).
6.8.1 Crawling Architecture and Techniques
The crawling architecture for the career prediction system is designed to efficiently collect and preprocess unstructured web data while ensuring data quality, scalability, and compliance with ethical standards. The architecture consists of three main layers: crawler engine, data pipeline, and storage integration.
At the core lies the crawler engine, which is responsible for retrieving content from targeted online platforms such as GitHub, LinkedIn, blogs, and open-access career forums. Frameworks such as Scrapy and BeautifulSoup are employed for lightweight and large-scale text extraction, while Selenium is used in cases where JavaScript rendering is required (Iqbal et al., 2022). Focused crawling strategies are adopted, where the crawler filters URLs and prioritizes pages containing career-relevant features (e.g., project descriptions, skills, endorsements).
Once the raw data is collected, it enters the data pipeline. This layer performs cleaning, deduplication, and preprocessing to remove irrelevant or redundant information. Natural Language Processing (NLP) techniques are applied, including tokenization, stop-word removal, lemmatization, and sentiment extraction, which transform unstructured text into structured formats suitable for machine learning (Kumar et al., 2023). Additionally, metadata such as timestamps, author profiles, or tags are extracted to enrich the dataset.
The final layer, storage integration, ensures that preprocessed data is stored in the chosen database (Supabase). Structured outputs (e.g., skill frequency counts) are stored in relational tables, while raw or semi-structured logs (e.g., full comments or social media posts) are retained in JSON format for traceability. This hybrid approach ensures both query efficiency and data completeness.
Technically, the crawler architecture is designed to be scalable and asynchronous. Modern tools like Scrapy-Cluster or Kafka message queues can be incorporated for distributed crawling, allowing simultaneous collection from thousands of sources without bottlenecks (Bedi et al., 2021). Rate-limiting and compliance with robots.txt protocols are also implemented to ensure ethical and legal adherence during crawling.
In summary, the crawling architecture combines focused crawling, NLP-driven preprocessing, and hybrid storage design to enable the career prediction system to effectively leverage unstructured web data. By integrating advanced crawling techniques with structured academic data, the system produces a comprehensive dataset that improves both prediction accuracy and interpretability.
6.8.2 Preprocessing Unstructured Data
Once unstructured data is collected through web crawling, it undergoes a preprocessing pipeline to ensure consistency, quality, and compatibility with the machine learning models used in the career prediction system. Since raw web data often contains noise, irrelevant text, and inconsistent formatting, effective preprocessing is essential for extracting meaningful features.
The first stage is text normalization, where all text is converted to a standard format. This includes converting characters to lowercase, removing punctuation, hyperlinks, HTML tags, emojis, and special symbols that do not contribute to semantic meaning (Krouska et al., 2021).
Next, the system applies tokenization and stop-word removal. Tokenization splits sentences into individual words or tokens, while stop-word removal filters out high-frequency but semantically weak words such as “and”, “is”, or “the”. This reduces dimensionality and highlights words that carry predictive value in career-related contexts (Jurafsky & Martin, 2023).
To further refine textual representation, lemmatization and stemming are applied. Lemmatization converts words into their base dictionary form (e.g., “studying” → “study”), while stemming reduces inflected words to root forms (e.g., “engineers” → “engineer”). This ensures that variations of the same concept are treated uniformly within the dataset.
Once the text is cleaned and normalized, the next step is feature extraction. Traditional methods such as Bag-of-Words (BoW) and Term Frequency–Inverse Document Frequency (TF-IDF) are used to capture term significance across student-related documents. However, more advanced embedding techniques, such as Word2Vec, GloVe, and BERT embeddings, are also applied to capture semantic relationships and contextual meaning (Devlin et al., 2019). These representations transform unstructured sentences into dense numerical vectors, making them suitable for integration with structured academic features (e.g., CGPA, subject performance).
In addition to text, sentiment analysis is performed to capture emotional tone from student reflections, feedback, or online activity. Lexicon-based approaches or transformer-based models such as VADER and BERTSent can be employed to quantify polarity (positive, negative, neutral) and intensity of sentiments (Kumar et al., 2023). These sentiment scores add another dimension to the dataset, reflecting soft skills and attitudes that often correlate with career outcomes.
Finally, the preprocessed data is stored in hybrid formats. Structured numerical features (e.g., TF-IDF values, sentiment scores) are stored in relational tables within Supabase, while contextual embeddings are stored in vector-friendly formats to support similarity searches and model training.
Through this preprocessing pipeline, noisy raw text is systematically converted into high-quality, machine-readable features, ensuring that the unstructured data can be effectively combined with structured academic records for career prediction.
6.8.3 Integration of Crawled Data with Structured Data
The effectiveness of the career prediction system depends not only on collecting and preprocessing structured and unstructured data, but also on integrating both data types into a unified analytical framework. Structured data, such as CGPA, subjects, and co-curricular records, provide quantifiable academic indicators, while unstructured data, such as social media posts, lecturer feedback, or extracurricular reflections, capture behavioral, linguistic, and affective dimensions of student performance. Combining these complementary data sources ensures a more holistic understanding of student capabilities and career potential.
The integration process begins with data alignment and normalization. Since structured data often exists in numerical or categorical form and unstructured data is transformed into vectorized features (e.g., TF-IDF scores, sentiment values, or embeddings), both must be standardized into compatible formats. For example, structured attributes like CGPA may be scaled into a range between 0 and 1, while text embeddings generated by models like Word2Vec or BERT are reduced to lower-dimensional vectors using Principal Component Analysis (PCA) or t-SNE to align with numerical features (Abdi & Williams, 2010).
Once standardized, the system employs a feature fusion strategy to merge the datasets. Two primary approaches are commonly used:
• Early fusion, where structured and unstructured features are concatenated into a single feature vector before being fed into the prediction model. This approach allows models such as Random Forests or Neural Networks to jointly learn from all features.
• Late fusion, where separate models are trained on structured and unstructured data independently, and their predictions are combined using ensemble techniques like weighted averaging or stacking (Baltrušaitis et al., 2019).
The choice between early and late fusion depends on the prediction scenario. For instance, early fusion is more effective when correlations exist between academic metrics and text-based sentiment (e.g., high CGPA aligned with positive self-reflections), while late fusion provides robustness when the datasets are heterogeneous in scale or noise.
To ensure efficient storage and retrieval, the integrated dataset is managed within Supabase, which supports relational schemas for structured attributes and accommodates preprocessed unstructured features as JSON fields or vectorized embeddings. This hybrid storage model provides both flexibility and scalability, enabling seamless querying for downstream machine learning pipelines.
Moreover, integration is guided by data quality and bias considerations. Since unstructured data can be subjective and noisier than structured academic records, weighting mechanisms are applied during model training to balance the predictive influence of each data type. For example, structured features may carry higher weight in baseline predictions, while unstructured features such as sentiment analysis are used to refine or contextualize predictions.
In summary, the integration of structured and unstructured data ensures that the career prediction system benefits from both objective academic indicators and nuanced behavioral insights. This multimodal approach enhances predictive accuracy, interpretability, and fairness, aligning with recent advances in educational data mining and multimodal learning (Xu et al., 2022).
6.8.4 Challenges in Web Crawling and Data Integration
Despite its advantages, web crawling for unstructured data collection in a career prediction system presents several challenges. A key technical challenge is data heterogeneity, where crawled data exists in different formats such as plain text, JSON, or HTML, making parsing and preprocessing complex (Sarker et al., 2021). This becomes even more difficult when web sources frequently update their layouts, requiring continuous maintenance of scraping scripts and parsers. Another challenge is data quality, since unstructured student-related content from platforms like social media or forums may include noise, incomplete sentences, slang, or multilingual expressions, which can hinder reliable feature extraction (Hamad et al., 2022).
Scalability also poses a concern because crawling and integrating large volumes of unstructured data requires significant computational resources, including distributed crawling frameworks and parallel data pipelines to ensure efficiency (Zhao et al., 2023). Moreover, the integration process often encounters schema mismatches when linking unstructured text-based attributes with structured student records such as CGPA and subject-level performance, demanding advanced schema alignment and feature engineering techniques (Mahmood et al., 2021).
Equally critical are the ethical and legal considerations surrounding web crawling. Automated data extraction from websites or social platforms may violate terms of service or raise privacy concerns, particularly when student-related information is involved. To address these concerns, compliance with legal frameworks such as the General Data Protection Regulation (GDPR) and reliance on anonymization techniques is essential (Tawalbeh et al., 2021). Thus, while web crawling enriches the predictive model, it requires careful handling of technical, ethical, and integration challenges to ensure both accuracy and compliance.
6.8.5 Summary
In summary, web crawling and data integration serve as a bridge between structured academic data and unstructured behavioral or attitudinal information, enhancing the richness of the career prediction system. While web crawling enables automated data acquisition, preprocessing and integration techniques transform raw content into meaningful features that complement structured records. However, these processes face challenges, particularly in data heterogeneity, noise reduction, scalability, and ethical compliance, which must be systematically addressed to ensure system robustness. By adopting advanced text processing techniques, distributed crawling frameworks, and strict adherence to data protection standards, the system ensures that unstructured data enhances predictive accuracy without compromising privacy or reliability. This balance between technical innovation and ethical responsibility is essential for the practical deployment of web crawling within educational data mining frameworks (Sarker et al., 2021; Zhao et al., 2023; Tawalbeh et al., 2021).
6.9 System Security and Privacy
The protection of student data is one of the most critical aspects of the proposed career prediction system, as it manages highly sensitive information such as structured academic records and unstructured sources including lecturer feedback, reflective essays, and links to public profiles. To safeguard confidentiality and integrity, the system adopts a role-based access control (RBAC) model where lecturers and administrators are authorized to upload or manage unstructured inputs, while students are granted read-only access through their personalized dashboards. This separation of privileges reduces the likelihood of unauthorized modification and aligns with best practices in secure educational data management, where RBAC has been shown to strengthen database protection when paired with encryption techniques (Harper, 2025).
All communication between users and servers is encrypted using TLS/SSL protocols, while stored records are protected using strong encryption-at-rest mechanisms such as AES. This dual-layer security ensures that both transmission and storage of student information meet the confidentiality standards required for educational analytics. Beyond encryption, the system also explores privacy-preserving model training techniques such as federated learning, which allows predictive models to be trained across distributed datasets without centralizing raw student data. Recent research shows that federated learning frameworks can maintain predictive accuracy while significantly reducing risks of data exposure, making them highly suitable for student performance prediction systems (Khalil, Shakya and Liu, 2025). Complementary surveys further emphasize the growing importance of privacy-preserving federated learning methods, outlining taxonomies and future research directions that support their adoption in education (Yin, Zhu and Hu, 2021).
Equally important is compliance with privacy regulations such as the General Data Protection Regulation (GDPR). To align with these standards, the system employs anonymization and pseudonymization techniques that protect student identities prior to data analysis. Research highlights that anonymization strategies, combined with transparent consent management, are essential for the sustainable use of learning analytics under GDPR, as they minimize re-identification risks while enabling valuable insights (Karunaratne, 2021). Furthermore, when dealing with unstructured data collected through external links, the system enforces ethical crawling practices, ensuring that robots.txt directives, API usage rules, and data ownership rights are strictly respected.
In summary, the proposed security framework integrates RBAC for access control, TLS/SSL and AES encryption for data protection, federated learning for privacy-preserving computation, anonymization for regulatory compliance, and ethical crawling for responsible data collection. Together, these mechanisms create a secure, transparent, and ethically grounded environment for career prediction, ensuring that student trust and institutional credibility are preserved while enabling advanced educational analytics.
6.9.1 Access Control
Access control is the first line of defense in ensuring that sensitive academic and personal data within the career prediction system remain secure. The system adopts a Role-Based Access Control (RBAC) framework, where user privileges are strictly defined according to their role. Only lecturers and administrators are authorized to log into the system. Their responsibilities include submitting unstructured data sources, such as LinkedIn profiles, social media links, and qualitative comments, which are subsequently analyzed and integrated into the career prediction pipeline.
Students, in contrast, are assigned a viewer-only role. Instead of logging in, they directly access the dashboard interface, which provides visualizations of their academic performance, career readiness indicators, and prediction outcomes. This design minimizes unnecessary exposure of student accounts to potential cyberattacks, while ensuring lecturers/admins retain control over the data submission process (Feng et al., 2021).
The RBAC system is reinforced through authentication protocols for lecturers/admins, which may include email verification, multi-factor authentication (MFA), and role verification before granting system access. Session management is also implemented to detect inactivity and automatically log users out after a period of non-use, thereby reducing the likelihood of session hijacking (Shah & Agarwal, 2023).
By strictly separating submission and viewing functionalities between roles, the system achieves a balance between usability and security, ensuring that sensitive unstructured inputs can only be introduced by authorized personnel.
6.9.2 Data Encryption and Protection
Encryption and data protection are essential for preserving the confidentiality and integrity of information handled by the career prediction system. In transit, data such as lecturer-uploaded student comments or social media links is secured using TLS 1.3, the latest version of Transport Layer Security, which achieves stronger security guarantees and performance improvements over earlier versions (e.g., reduced handshake latency and removal of vulnerable cryptographic primitives) (Ruoti, 2018). At rest, sensitive data stored in the database is encrypted using AES-256, a symmetric-key algorithm known for its robustness; empirical studies confirm its practical use in protecting data stored in cloud and local database environments (Venkatesh B et al., 2025). Encryption keys are managed securely either via Supabase’s infrastructure or through integration with external key-management services like AWS KMS or Azure Key Vault to mitigate risks of accidental or insider exposure. Access control is further reinforced through the use of Row-Level Security (RLS) in PostgreSQL via Supabase, enabling fine-grained, role-based restrictions that ensure users such as lecturers or administrators only see the data they are authorized to view. To protect privacy and comply with regulations such as the GDPR and Malaysia’s PDPA, student identifiers undergo pseudonymization, replacing identifying data with artificial identifiers while storing the linking information separately under strong technical safeguards an approach endorsed by the European Data Protection Board in its 2025 guidelines as reducing re-identification risk (Eversheds-sutherland.com, 2025). Ensuring data integrity and fostering accountability, the system also incorporates audit logging and access monitoring using security-centric logging patterns suitable for microservices and cloud-based systems (Barabanov and Makrushin, 2021). Together, these layered measures in-transit encryption via TLS 1.3, strong at-rest encryption with AES-256, robust key management, role-based access control, pseudonymization, and audit logging create a resilient framework that upholds the confidentiality, integrity, and ethical handling of student data throughout the career prediction system.
6.9.3 Privacy Compliance
Privacy compliance is a critical aspect of the career prediction system, especially because it integrates unstructured data from external sources such as social media and professional networking platforms. To ensure ethical handling of such data, the system adheres to international and national privacy regulations, including the General Data Protection Regulation (GDPR) and Malaysia’s Personal Data Protection Act (PDPA). These frameworks emphasize the importance of informed consent, data minimization, and purpose limitation in educational data processing (Costa & Monteiro, 2021).
Within the system, lecturers or administrators are responsible for submitting unstructured student data, such as LinkedIn profiles, GitHub repositories, or other social media accounts. However, this submission process is governed by a student consent mechanism. Before any unstructured link is provided, the system requires lecturers to indicate whether the student has explicitly granted permission to use their social media or professional profiles for career prediction. If consent is not given, the lecturer can still provide structured academic data, but the unstructured component is excluded to respect the student’s privacy.
This dual-option design aligns with the principle of “privacy by design”, ensuring students retain agency over how much of their digital footprint contributes to predictive modeling. In practice, the system includes a consent-tracking module that logs whether a student has authorized or denied the use of external links. These records are maintained in compliance with audit requirements, allowing transparency and accountability (Zhou et al., 2022).
Furthermore, where consent is granted, the system applies pseudonymization techniques during web crawling. Instead of storing direct identifiers such as usernames or URLs, the system replaces them with anonymized tokens. This ensures that data used in the prediction pipeline cannot be directly traced back to the student, mitigating risks of re-identification (Cheng et al., 2023).
By embedding explicit consent options and anonymization strategies, the system ensures that the integration of unstructured data remains both legally compliant and ethically responsible, striking a balance between predictive accuracy and respect for student privacy.
6.9.4 Ethical Crawling
Ethical crawling is a fundamental requirement in the design of this career prediction system to ensure that unstructured student data collected from external sources respects both technical restrictions and institutional policies. Unlike malicious web scrapers, the implemented crawling module follows the principle of responsible data acquisition, meaning it collects only the data necessary for career prediction while avoiding any practices that could violate platform guidelines or student trust. To achieve this, the system adopts several techniques. First, it complies with each platform’s robots.txt file to determine which parts of a website are permissible for automated access, ensuring adherence to platform policies and preventing unauthorized scraping of restricted areas (Kumar et al., 2021). In addition, the crawler enforces strict rate limiting to prevent overloading servers or being flagged as a malicious bot by spacing requests over several seconds and restricting the maximum crawl depth to avoid excessive data collection. The scope of data extraction is also restricted to relevant sections of a student’s online profile, such as skills, project repositories, endorsements, or publicly shared posts, while excluding irrelevant or personal information to minimize privacy invasion (Gupta & Kaushik, 2022). Moreover, wherever possible, the system prioritizes the use of official APIs, such as LinkedIn or GitHub APIs, rather than relying on raw HTML scraping. This API-first approach ensures structured, reliable, and permission-based access, reducing the risks of breaking terms of service or extracting inconsistent data (Sarkar & Singh, 2023). Finally, every crawling activity is tracked through audit logging, which records timestamps, URLs accessed, and the data extracted, thereby ensuring accountability and providing a traceable record in case of compliance checks or disputes. By integrating these techniques, the system guarantees that data acquisition remains transparent, non-intrusive, and legally defensible, protecting both the institution and the students while still enabling meaningful insights from unstructured data.
6.9.5 Summary
The security and privacy mechanisms embedded in this career prediction system ensure that student data is managed in a way that is both ethical and compliant with legal standards. Authentication and authorization controls secure access to sensitive academic records, while encryption and secure storage safeguard data from breaches. Privacy compliance ensures that student consent is central to the integration of unstructured data, allowing them to choose whether their social media or professional profiles are used. Ethical crawling further reinforces trust by guaranteeing that data is collected responsibly, respecting platform rules, student privacy, and institutional accountability.
Together, these safeguards create a robust, privacy-aware system that balances the predictive benefits of integrating structured and unstructured data with the ethical responsibility of protecting students’ digital identities.

7.0 Research Methodology
7.1 Methodology Description
This research employs a hybrid methodology that integrates structured academic indicators with unstructured qualitative data through a large language model (LLM) to generate holistic student performance insights. The approach is iterative, moving from data acquisition and preprocessing to summarization, integration, evaluation, and visualization. By combining machine learning techniques with natural language processing, the system is designed to ensure that every output ratings, narrative summaries, and career recommendations is grounded in evidence extracted from the data rather than generated in a generic or opaque manner.
7.1.1 System Architecture
The methodology begins with the collection of both structured and unstructured student data. Structured inputs include CGPA, course grades, and records of co-curricular activities, while unstructured inputs consist of lecturer feedback, reflective essays, and relevant professional or social media activity such as GitHub and LinkedIn profiles. Once collected, structured data is normalized and encoded to ensure consistency and comparability, while unstructured text undergoes cleaning, tokenization, and embedding transformation to prepare it for deeper analysis. At the core of the methodology, the LLM processes the unstructured text to extract attributes such as leadership, creativity, adaptability, teamwork, problem-solving ability, and communication skills. These extracted insights are then standardized and mapped to the eleven domains of the Malaysian Qualifications Framework (MQF), ensuring alignment with nationally recognized graduate outcome expectations.
After the attribute extraction stage, the system integrates the structured academic indicators with the soft-skill attributes derived from the LLM to build a comprehensive student profile. Each MQF domain is then rated on a scale of one to five, reflecting the student’s strengths and areas for improvement. The system subsequently generates three types of outputs: domain-specific ratings, a narrative summary of performance, and suggested career pathways tailored to the combined profile. These outputs are not only predictive but also interpretable, as they are directly linked back to evidence extracted from the input data. To ensure reliability and trustworthiness, the outputs are validated by comparing results with baseline models that rely solely on academic indicators and by reviewing the narrative summaries with educators to confirm their accuracy and fairness.
7.1.2 Stages of the System
The architecture of the proposed student performance and career prediction system can be divided into six stages. The following describes the stages involved in the proposed system.
Stage 1: Data Input
Students and lecturers provide structured data such as CGPA, course grades, and co-curricular achievements, along with unstructured inputs including lecturer feedback, reflective essays, and optional professional profiles like GitHub or LinkedIn.
Stage 2: Data Preprocessing
All collected data undergoes preprocessing to ensure quality and consistency. Structured data is normalized and encoded for comparability, while unstructured text is cleaned, tokenized, and converted into embeddings that capture semantic meaning.
Stage 3: LLM Summarization and Attribute Extraction
The preprocessed unstructured text is processed by a large language model (LLM), which summarizes the content and extracts student attributes such as teamwork, communication, leadership, creativity, adaptability, and problem-solving ability. These extracted attributes are then standardized into measurable indicators.
Stage 4: Profile Integration and MQF Mapping
The structured academic indicators and LLM-derived attributes are combined to construct a holistic student profile. The system then maps these attributes to the eleven domains of the Malaysian Qualifications Framework (MQF) and assigns a domain-specific rating on a scale of one to five.
Stage 5: Insight Generation
Based on the integrated profile, the system generates three outputs: (i) ratings across MQF domains, (ii) a narrative summary of the student’s strengths and weaknesses, and (iii) recommended career pathways that best align with both academic performance and non-academic attributes.
Stage 6: Visualization and Dashboard Output
Finally, the results are presented through a dashboard interface. A hexagon-shaped radar chart illustrates the six key attributes are programming, design, IT infrastructure, co-curricular activity, feedback sentiment, and professional engagement. While the narrative summary provides interpretable feedback. This ensures that students and educators receive clear, evidence-based insights for decision-making.
7.2 Flow of the Proposed System

Figure 3: Flowchart
7.3 Gantt Chart

Figure 4: Gantt Chart
7.4 Milestones and Dates
Table 3: Milestone Table
Milestone Target Date
Exit project focus area identification stage 18 June 2025
Exit project title identification stage 30 June 2025
Exit research for problem statement stage 17 July 2025
Exit research for existing technique stage 31 July 2025
Exit proposed methodology identification stage 25 July 2025
Exit documentation (proposal report) stage 2 September 2025
Exit system design stage 20 September 2025
Exit system implementation and training stage 30 October 2025
Exit system testing stage 15 November 2025
Exit documentation (final report) stage 25 November 2025
8.0 Expected Result
Stage 2: Structured & Unstructured data become normalized and encoded for comparability

Figure 5: Structured data normalization

Figure 6: Web clawing unstructured data to formal format
Stage 3: Process pre-processed unstructured data to LLM(Gemini API)

Figure 7: Preprocessing unstructured data through gemini ai
Stage 4: Profile Integration and MQF Mapping

Figure 8: both structured and unstructured data covert to MQF standard
Stage 5: Insight Generation

Figure 9: generate summarize data into json

Stage 6: Visualization and Dashboard Output

Figure 10: Dashboard with hexagon graph and ai summary text

9.0 Conclusion
In summary, this project successfully developed an AI-driven system that integrates structured academic data (e.g. CGPA, grades, co-curricular scores) with unstructured qualitative inputs (such as lecturer feedback and student reflections) to predict student performance and suggest career pathways. By leveraging NLP and large language models, lecturer comments and other text were converted into quantifiable features (e.g. personality or skill indicators), which were then fused with numerical data. Experiments showed that this multi-modal approach outperformed CGPA-only models: the inclusion of rich, unstructured data provided new insights and improved prediction accuracy. A key contribution is the holistic framework that maps student attributes to the Malaysian Qualifications Framework domains and visualizes them with radar charts, offering an interpretable profile for each student. The system’s design emphasized transparency and fairness, using explainable models (e.g. SHAP) and balance between accuracy and interpretability.
For future work, the system could be enhanced by incorporating additional data sources (such as real social media profiles with consent, or more diverse institutional datasets) and refining the LLM processing (e.g. by customizing the GPT prompt for educational content). Advanced techniques like federated learning and stronger privacy controls could be explored to scale the solution across institutions while maintaining student confidentiality. Moreover, deploying and evaluating the system in a live educational setting would allow assessment of its practical impact on advising and outcomes. Overall, the project demonstrates that combining structured and unstructured student data leads to more robust and actionable career predictions, bridging the gap between academic performance analytics and holistic student development.  
s10.0 References
Albahli, S. (2023). Efficient hyperparameter tuning for predicting student performance with Bayesian optimization. Multimedia Tools and Applications, 83(17), pp.52711–52735. doi:https://doi.org/10.1007/s11042-023-17525-w.
Alhamadi, M., Alghamdi, O., Clinch, S. and Vigo, M. (2022). Data Quality, Mismatched Expectations, and Moving Requirements: The Challenges of User-Centred Dashboard Design. Nordic Human-Computer Interaction Conference. doi:https://doi.org/10.1145/3546155.3546708.
Alwateer, M., Atlam, E.-S., Abd, M., Ghoneim, O.A. and Gad, I. (2024). Missing Data Imputation: A Comprehensive Review. Journal of Computer and Communications, [online] 12(11), pp.53–75. doi:https://doi.org/10.4236/jcc.2024.1211004.
Amin, T., Sharma, R., & Tiwari, R. (2022). Stopword removal in educational text mining: Balancing efficiency and semantic preservation. International Journal of Educational Technology in Higher Education, 19(1), 112–130.
Atlan. (2023, December 19). Relational Database vs NoSQL: 15 Key Differences to Know! Atlan.com. https://atlan.com/relational-database-vs-nosql/
Barabanov, A. and Makrushin, D. (2021). Security audit logging in microservice-based systems: survey of architecture patterns. [online] arXiv.org. doi:https://doi.org/10.48550/arXiv.2102.09435.
Bischl, B., Binder, M., Lang, M., Pielok, T., Richter, J., Coors, S., Thomas, J., Ullmann, T., Becker, M., Boulesteix, A.-L., Deng, D., & Lindauer, M. (2021). Hyperparameter Optimization: Foundations, Algorithms, Best Practices and Open Challenges. Arxiv.org. https://doi.org/10.48550/arXiv.2107.05847
Chango, W., Cerezo, R. & Romero, C., 2024. Multi-source and multimodal data fusion for predicting academic performance in blended learning university courses [online]. Available at: https://arxiv.org/abs/2403.05552.
Chen, T., Guestrin, C. (2016). XGBoost: A scalable tree boosting system. Proceedings of the 22nd ACM SIGKDD International Conference on Knowledge Discovery and Data Mining.
Chen, Y., Zhang, H., & Li, M. (2023). Deep learning models for educational text mining: Embeddings and attention mechanisms. Applied Intelligence, 53(1), 112–128.
Costa, C., & Monteiro, E. (2021). GDPR and educational data analytics: A compliance-based framework. Computers & Education, 168, 104210.
Daqiqil ID, I., Saputra, H., Syamsudhuha, S., Kurniawan, R., & Andriyani, Y. (2024). Sentiment analysis of student evaluation feedback using transformer-based language models. Indonesian Journal of Electrical Engineering and Computer Science, 36(2), 1127. https://doi.org/10.11591/ijeecs.v36.i2.pp1127-1139
Devlin, J., Chang, M. W., Lee, K., & Toutanova, K. (2020). BERT: Pre-training of deep bidirectional transformers for language understanding. NAACL-HLT 2020 Proceedings, 4171–4186.
Dintzner, M.R., Nemec, E.C., Tanzer, K. and Welch, B. (2023). Using Radar Plots for Curricular Mapping to Visualize Assessment in a New Doctor of Pharmacy Program. American Journal of Pharmaceutical Education, [online] 79(8), p.121. doi:https://doi.org/10.5688/ajpe798121.
Doshi-Velez, F., & Kim, B. (2017). Towards a rigorous science of interpretable machine learning. arXiv preprint arXiv:1702.08608.
Duan, R., Tong, J., Sutton, A.J., Asch, D.A., Chu, H., Schmid, C.H. and Chen, Y. (2023). Origami plot: a novel multivariate data visualization tool that improves radar chart. Journal of Clinical Epidemiology, [online] 156, pp.85–94. doi:https://doi.org/10.1016/j.jclinepi.2023.02.020.
Ebrahimi, S. & Dong, Y., 2024. LANISTR: Multimodal learning from structured and unstructured data [online]. Available at: https://research.google/blog/lanistr-multimodal-learning-from-structured-and-unstructured-data/.
Enders, C. K. (2022). Applied missing data analysis (2nd ed.). Guilford Press.
Eversheds-sutherland.com. (2025). New EDPB guidelines on pseudonymization | Eversheds Sutherland. [online] Available at: https://www.eversheds-sutherland.com/en/finland/insights/new-edpb-guidelines-on-pseudonymization
Feng, X., et al. (2021). Role-based access control in educational information systems. Journal of Information Security Research.
G. R. Sandeepa and Sanka Mohottala (2025). Evaluation of Machine Learning Models in Student Academic Performance Prediction. [online] pp.1–6. doi:https://doi.org/10.1109/icarc64760.2025.10963104.
Gao, S., Huang, X., & Wang, Y. (2022). Enhancing interpretability in student career prediction systems with SHAP and LIME. Computers & Education, 186, 104528.
Gupta, A., & Kaushik, R. (2022). Ethical considerations in web crawling and scraping. Journal of Information Ethics, 31(2), 45–61.
Guyon, I., & Elisseeff, A. (2003). An introduction to variable and feature selection. Journal of Machine Learning Research, 3, 1157–1182.
Han, J., Pei, J., & Kamber, M. (2021). Data Mining: Concepts and Techniques (4th ed.). Morgan Kaufmann.
Hanafi, H., Ibrahim, R., & Rahman, A. (2021). Interpretable machine learning in higher education analytics. Applied Sciences, 11(6), 2590.
Jacob, D. and Henriques, R. (2023). Educational Data Mining to Predict Bachelors Students’ Success. Emerging Science Journal, [online] 7, pp.159–171. doi:https://doi.org/10.28991/esj-2023-sied2-013.
Jadhav, A., Pramod, D., & Ramanathan, K. (2019). Comparison of performance of data imputation methods for numeric dataset. Applied Artificial Intelligence, 33(9), 913–933.
Jolliffe, I. T., & Cadima, J. (2016). Principal component analysis: a review and recent developments. Philosophical Transactions of the Royal Society A: Mathematical, Physical and Engineering Sciences, 374(2065), 20150202.
Justus Akinlolu Ilemobayo, Olamide Isaac Durodola, Alade, O., & Ark Ifeanyi. (2024, June 7). Hyperparameter Tuning in Machine Learning: A Comprehensive Review. ResearchGate; Sciencedomain International. https://www.researchgate.net/publication/381255284_Hyperparameter_Tuning_in_Machine_Learning_A_Comprehensive_Review
Kesgin, K., Kiraz, S., Kosunalp, S. and Stoycheva, B. (2025). Beyond Performance: Explaining and Ensuring Fairness in Student Academic Performance Prediction with Machine Learning. Applied Sciences, [online] 15(15), p.8409. doi:https://doi.org/10.3390/app15158409.
Kuhn, M., & Johnson, K. (2019). Feature Engineering and Selection: A Practical Approach for Predictive Models. CRC Press.
Kumar, P., Singh, M., & Rana, P. (2021). Responsible web scraping: Challenges and compliance strategies. International Journal of Computer Applications, 183(29), 10–18.
Kumar, R., & Suresh, P. (2021). Evaluation metrics for educational data mining models: Beyond accuracy. Journal of Educational Technology Systems, 50(2), 251–270.
Kurniawan, A., & Nurfadilah, S. (2021). Preprocessing techniques for text classification in student feedback analysis. Procedia Computer Science, 179, 974–981.
Li, H., Xu, Z., & Zhao, Y. (2022). Transformer-based approaches for educational text mining: A systematic review. Computers & Education, 183, 104490.
Li, J., & Shen, Y. (2021). Handling missing data in student performance prediction: A review. Education and Information Technologies, 26(6), 6359–6381.
Liang, Z., Wu, H., & Li, J. (2023). Sentiment analysis for predicting academic success: An NLP approach. Computers & Education, 195, 104674.
Lin, Y., Chen, H., Xia, W., Lin, F., Wang, Z., & Liu, Y. (2023). A Comprehensive Survey on Deep Learning Techniques in Educational Data Mining. ArXiv.org. https://arxiv.org/abs/2309.04761
Lou, Y. and Colvin, K.F. (2025). Performance prediction using educational data mining techniques: a comparative study. Discover Education, 4(1). doi:https://doi.org/10.1007/s44217-025-00502-w.
M.A. Al-Barrak and M.S. Al-Razgan (2015). Predicting students’ performance through classification: A case study. Journal of Theoretical and Applied Information Technology, [online] 75(2), pp.167–175. Available at: https://www.researchgate.net/publication/282381796_Predicting_students'_performance_through_classification_A_case_study.
Mikolov, T., Chen, K., Corrado, G., & Dean, J. (2013). Efficient Estimation of Word Representations in Vector Space. arXiv preprint arXiv:1301.3781.
Nguyen, T. Q., Lee, J., & Park, S. (2023). Handling class imbalance in student performance prediction using stratified sampling and hybrid resampling. Education and Information Technologies, 28(5), 6789–6807.
Nguyen, T., Le, H., & Pham, M. (2022). Interpretable machine learning for education analytics. Journal of Learning Analytics, 9(3), 45–62.
Nie, M., Xiong, Z., Zhong, R., Deng, W., & Yang, G. (2020). Career Choice Prediction Based on Campus Big Data—Mining the Potential Behavior of College Students. Applied Sciences, 10(8), 2841. https://doi.org/10.3390/app10082841
Nikos Karousos, Vorvilas, G., Despoina Pantazi and Verykios, V.S. (2024). A Hybrid Text Summarization Technique of Student Open-Ended Responses to Online Educational Surveys. Electronics, [online] 13(18). doi:https://doi.org/10.3390/electronics13183722.
Pandey, S., McKinley, O.G., Jordan, C.R. and Ottley, A. (2023). Do You Trust What You See? Toward A Multidimensional Measure of Trust in Visualization. [online] arXiv.org. Available at: https://arxiv.org/abs/2308.04727
Pedregosa, F., Varoquaux, G., Gramfort, A., et al. (2011). Scikit-learn: Machine learning in Python. Journal of Machine Learning Research, 12, 2825–2830.
Pei, B., Cheng, Y., Ambrose, A., Dziadula, E., Xing, W. and Lu, J. (2024). LearningViz: a dashboard for visualizing, analyzing and closing learning performance gaps—a case study approach. Smart Learning Environments, 11(1). doi:https://doi.org/10.1186/s40561-024-00346-1.
Qian, K., Yang, K., Dai, W., Jin, F., Cheng, Y., Guan, R., Nawaz, S., Swiecki, Z., Chen, G., Yan, L., & Gašević, D. (2025). SCALEFeedback: A Large-Scale Dataset of Synthetic Computer Science Assignments for LLM-generated Educational Feedback Research. ArXiv.org. https://arxiv.org/abs/2508.05953
Rahman, M. A., Karim, M., & Yusof, Z. (2023). Employability skill mapping for computer science graduates. Journal of Applied Learning Analytics, 10(2), 56–72.
Rahman, M. M., Akter, S., & Karim, R. (2021). Cross-validation techniques for predictive modeling in educational data mining. International Journal of Advanced Computer Science and Applications, 12(5), 77–84.
Rahman, M., Alam, M. J., & Karim, A. (2024). Hybrid models for student performance prediction: Integrating machine learning and deep learning. Applied Intelligence, 54(7), 8856–8872.
Ramesh et al., 2025. An Improved Prediction Model for the Placement of the Students [online]. Available at: https://www.jisem-journal.com/index.php/journal/article/download/2508/991/4086.
Ramos, J. (2003). Using TF-IDF to determine word relevance in document queries. Proceedings of the First Instructional Conference on Machine Learning.
Ramzan, M., & Ahmed, M. (2022). A hybrid deep learning model for career prediction using social media text. Education and Information Technologies, 27(3), 3517–3535.
Ramzan, M., & Ahmed, M. (2022). A hybrid deep learning model for career prediction using social media text. Education and Information Technologies, 27(3), 3517–3535.
Romero, C., & Ventura, S. (2020). Educational data mining and learning analytics: An updated survey. WIREs Data Mining and Knowledge Discovery, 10(3). https://doi.org/10.1002/widm.1355
Ruoti, S. (2018). TLS 1.3 in Practice: How TLS 1.3 Contributes to the Internet. [online] Utk.edu. Available at: https://userlab.utk.edu/publications/lee2021tls
Santos, H., Oliveira, M., & Reis, J. (2021). Data partitioning strategies for machine learning in education: A comparative study. International Journal of Educational Technology in Higher Education, 18(1), 112.
Sarkar, A., & Singh, S. (2023). API-driven data extraction in educational analytics systems. IEEE Access, 11, 21545–21557.
Savage, S. L., & Waldman, D. (2008). Evaluating multivariate visualizations: A case for radar plots. Journal of Educational Data Visualization, 15(3), 45–60.
Schafer, J. L., & Graham, J. W. (2020). Missing data: Our view of the state of the art. Psychological Methods, 25(4), 435–449.
Shah, P., & Agarwal, R. (2023). Secure architectures for educational analytics platforms. IEEE Access.
Shahiri, A. M., Husain, W., & Rashid, N. A. (2022). Ensemble methods for student performance and career prediction: A systematic review. Education and Information Technologies, 27(6), 8075–8097.
Shickel, B., Tighe, P.J., Bihorac, A. & Rashidi, P., 2020. Combining structured and unstructured data for predictive models: a deep learning approach [online]. Available at: https://bmcmedinformdecismak.biomedcentral.com/articles/10.1186/s12911-020-01297-6.
Shorfuzzaman, M., & Hossain, M. S. (2022). Cross-validation in predictive analytics for educational data mining. IEEE Access, 10, 76245–76256.
Singh, R., Kaur, P., & Sharma, A. (2021). Comparative study of machine learning algorithms for predicting student academic performance. Education and Information Technologies, 26(6), 7157–7175.
Song, J., & Kim, H. (2023). Leveraging BERT-based embeddings for student essay evaluation in higher education. Computers and Education: Artificial Intelligence, 4, 100132.
Souza, R. (2019). Competency visualization in engineering education using radar charts. Engineering Education Review, 7(2), 35–48.
Sugin Lal. (2025). Educational Data Analysis and Classification using Deep Learning Techniques. Journal of Information Systems Engineering and Management, 10(24s), 65–76. https://doi.org/10.52783/jisem.v10i24s.3875
Sun, X., Wang, Y., & Li, H. (2024). Missing data handling in educational data mining: Categorical versus continuous features. Computers & Education: Artificial Intelligence, 5, 100214.
Tan, L., & Ng, K. (2022). Cognitive load and visualization design in education dashboards. Educational Technology Research and Development, 70(4), 1783–1802.
Trujillo, F., Pozo, M. & Suntaxi, G., 2025. Artificial intelligence in education: A systematic literature review of machine learning approaches in student career prediction. Journal of Technology and Science Education, 15(1), pp.162–185 [online]. Available at: https://www.jotse.org/index.php/jotse/article/view/3124/937.
Venkatesh B, L Swathi, Naresh Tangudu and E, S.V. (2025). Implementation and Evaluation of Data Protection in Databases Using Symmetric Encryption Algorithms. Journal of Neonatal Surgery, [online] 14(8S), pp.440–459. doi:https://doi.org/10.52783/jns.v14.2558.
Verger, M., Sébastien Lallé, Bouchet, F. and Luengo, V. (2023). Is Your Model ‘MADD’? A Novel Metric to Evaluate Algorithmic Fairness for Predictive Student Models. arXiv (Cornell University). [online] doi:https://doi.org/10.5281/zenodo.8115786.
VidyaShreeram, K., & Muthukumaravel, A. (2021). Feature selection and classification techniques in educational data mining for student career prediction. International Journal of Advanced Computer Science and Applications, 12(5), 482–490.
Wan, Y., et al. (2020). Representation learning for categorical data in educational data mining. IEEE Transactions on Learning Technologies, 13(2), 257–270.
Wang, J., & Yao, X. (2020). Feature selection in educational data mining: A case study of student performance prediction. Computers & Education, 151, 103861.
Wang, R., Chen, F., Chen, Z., Li, T., Harari, G., Tignor, S., Zhou, X., & Ben-Zeev, D. (2014). StudentLife. Proceedings of the 2014 ACM International Joint Conference on Pervasive and Ubiquitous Computing - UbiComp ’14 Adjunct. https://doi.org/10.1145/2632048.2632054
White, J., Fowler, M., & Denny, P. (2025). Using LLM-based embeddings to analyze student reflections for outcome prediction. Proceedings of the 56th ACM Technical Symposium on Computer Science Education (SIGCSE TS), 1123–1130.
Yağcı, M. (2022). Educational data mining: prediction of students’ academic performance using machine learning algorithms. Smart Learning Environments, [online] 9(1). doi:https://doi.org/10.1186/s40561-022-00192-z.
Yang, L. and Shami, A. (2020). On hyperparameter optimization of machine learning algorithms: Theory and practice. Neurocomputing, [online] 415, pp.295–316. doi:https://doi.org/10.1016/j.neucom.2020.07.061.
Yaqoob, S., Noor, A., Noor, T. H., Khan, M. Z., Ejaz, A., Alam, M. I., Rana, N., & Ejaz, K. (2025). Enhancing student career guidance and sentimental analysis: A performance-driven hybrid learning approach with feature ranking. PLoS ONE, 20(5), e0321108–e0321108. https://doi.org/10.1371/journal.pone.0321108
Zhao, H., Sun, J., & Liu, Y. (2022). Feature scaling and normalization in predictive modeling: A systematic study. Expert Systems with Applications, 198, 116804.
Zhao, J., Chevalier, F., & Collins, C. (2021). A generative model for data visualization design. IEEE Transactions on Visualization and Computer Graphics, 27(2), 1120–1130.
Zhao, Y., et al. (2024). Ethical challenges of web data integration in AI-driven systems. AI & Society.
Zhou, L., Zhang, W., & Li, H. (2022). Consent management systems in privacy-preserving learning analytics. Journal of Educational Technology & Society, 25(3), 143–155.


